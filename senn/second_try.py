#!/usr/bin/python

# \todo: - how is rand initialised -- it seems always the same?


import numpy as np
from scitools.std import *

def delayperm(x,n):  # Circles the columns of matrix x to the right by n columns. 
    return np.roll(x, n, axis=1);


# Learning of the inverse and then the predictive inverse model for song generation. 
# Based on discussions with Richard and Surya, Jan 14, 2011. Bugs etc attributed to Walter.
# 
# Shared with Andre Gruning, 2015/10/19. Changes:
# - Oct 2015: updating comments
# - Oct 2015:  translate to pyhton.
# - 2015/11/02: replace random drive with fixed drive.
# - 2015/11/02: rename variable to better fit our current terminology
# - 2015/11/02: change from random drive of RA during inversion
#               learning to drive with one fixed pattern.
# - 2015/11/02: add error between actual sound and predicted sound via
#               LMAN -- this is lower than the error between the
#               motoric representations. -- Why? -- perhaps because
#               matrix S is contraxcting?
# - 2015/11/02  switch driving from direct injection into RA to
#               injection via HVC -- leads to same error of
#               causal-inverse learning
# - 2015/11/02  start weight copying in phase 2.

# number of motor neurons (RA)
n_ra = 50; # 3 for testing, or 7, n_ra=200; , currently 50 for testing
# on train

# dimension of song, ie number of "acoustic" degrees of freedom"
n_sound = n_ra; 

# number of auditory neurons which receive the sound and convert into neural activity.
n_aud = n_ra; 

# number of auditory memory neurons which memorize the tutor song (for one time step)
n_lman = n_ra; 

# duration of subsongs and of tutor song  [ms?]
T = 100; 

# Delay of auditory activity with respect to the generating motor activity (syrinx + auditory pathway) [ms?] -- isnt that rather in the area of 50ms-70ms?
tau = 10; 

# learning steps for model 
n_learn = 300; 

# 100 learning steps for predicitve inverse model (ie to learn direct
# connections from memory to motor neurons TO BE DELETED
nlearn_pred=1; 

eta_lman = 0.002; # learning rate for inverse model via lman.

eta_hvc = 0.001; # learning rate for weight copying

epsi = 1/10000; # Parameter to regularize the matrices to avoid near
# zero EV -- bad for inversion.

# syrinx; converts the RA motor activity signal m into a sound (here just matrix)
S = (np.random.randn(n_sound,n_ra) + epsi*np.eye(n_ra)) / sqrt(n_ra);

# auditory pathway; converts the song into an auditory signal for aud
# neurons (here just a matrix)
A = (np.random.randn(n_aud,n_sound) + epsi*np.eye(n_ra)) / sqrt(n_aud); 

# Total motor to auditory transformation. 
Q=A.dot(S); 

# acoustic representation of tutor song -- this what we start from.
song_sound_tut = np.random.randn(n_ra,T); 

# auditory representation of tutor song auditory -- generated by the 
# tutor song, or by rehearsing of the memory this is our imprint.
song_aud_tut = A.dot(song_sound_tut);

# initial weight matrix converting the auditory representation from
# LMAN into RA motor activity (inverse model) 
w_lman = np.random.randn(n_ra,n_aud) / sqrt(n_aud); 

# initial weight matrix from HVC to RA:
w_hvc=np.random.randn(n_ra,n_lman)/sqrt(n_lman); 

# Initialize error values for each learning step
e_lman_ra = np.zeros(n_learn); 
e_lman_sound = np.zeros(n_learn);
e_lman_sound2 = np.zeros(n_learn);
e_weight = np.zeros(n_learn);

for i in xrange(0,n_learn):

    # Phase B:
    # learning the inverse model from  babbling a subsong from HVC 
    # trying to reproduce the motor pattern it generated  
    # ie this is prospective learning.

    # fixed activity drives RA during imitation learning: 
    ra_soma=w_hvc.dot(song_aud_tut); # erronously I had driven here
#    ra_soma=w_hvc.dot(song_sound_tut); # erronously I had driven here
    # from song_sound_tut which let to a lower error? Is thsi a matter
    # of scaling? and I also get overlows nw with the correct
    # song_aud_tut. Scaling of Q, A, S?
    # das passiert by 50

    # auditory activity produced by the subsong 
    aud_soma=delayperm(Q.dot(ra_soma),tau); 

    # motor activity predicted from the auditory activity
    ra_pred=w_lman.dot(aud_soma); 
  
    # Difference between actual RA activity and predicted (via lman):
    diff_ra_lman=(delayperm(ra_soma,tau)-ra_pred); 

    sound_pred = S.dot(ra_pred); # from lman activity.
    
    diff_sound_lman = (delayperm(S.dot(ra_soma),tau) - sound_pred);
    diff_sound_tut = (delayperm(song_sound_tut,tau) - sound_pred);

    # weight change: dw = (m_t-Delta - ra_pred_t) * a (postdictive
    # learning, need trace of prior motor activity) for weights from
    # auditory to motoric representation.
    dw_lman=diff_ra_lman.dot(aud_soma.T); 

    # apply weight change
    w_lman=w_lman+eta_lman*dw_lman; 

    # Mean squared error in motor estimation per time step and motor
    # neuron 
    e_lman_ra[i]=(sum(diff_ra_lman*diff_ra_lman))/(T*n_ra);  # motoric
    e_lman_sound[i]=(sum(diff_sound_lman*diff_sound_lman))/(T*n_sound);  # in sound domain
    # in sound domain # in sound domain between lman predicted and tutor sound
    e_lman_sound2[i]=(sum(diff_sound_tut*diff_sound_tut))/(T*n_sound);  
    
    # This was Phase B -- inverse learning.
  
    # Now Phase C -- weight copying.
    # - driving from LMAN
    # - no actual acoustic feedback
    # - connections from HVC to RA are learning
    # as a consequence e_lman_sound2 should go down.
    
    lman_soma = song_aud_tut;
    ra_soma = w_lman.dot(song_aud_tut);

    hvc_soma = song_aud_tut;
    pre_hvc = hvc_soma;
    ra_dend_hvc =  w_hvc.dot(hvc_soma);  

    dw_hvc = (ra_soma - ra_dend_hvc).dot(pre_hvc.T)
    
    w_hvc = w_hvc + eta_hvc * dw_hvc; # for some reason += does not
    # deliver the result I want (probaly a problem with reference vs
    # value)  

    e_weight[i] = sum((w_hvc - w_lman)*(w_hvc - w_lman)) / (T*n_lman*n_ra);

#    e_weights[i]=(sum(d_weights*d_weights))/(T*n_hvc*n_ra); 



  
# print figure;

figure(1);
plot(e_lman_ra); 
xlabel('Learning steps'); 
ylabel('Error');
title('Inverse error of forced motoric activity at RA vs predicted motoric activity via LMAN$');
legend('SME between tutor motoric and "inverse" activitey via LMAN');

figure(2);
plot(e_lman_sound); 
xlabel('Learning steps'); 
ylabel('Error');
title('Inverse error between sound produced via actual RA vs predicitdc motoric activity via LMAN$');
legend('SME between actual sound and sound predicted by via LMAN');


figure(3);
plot(e_lman_sound2); 
xlabel('Learning steps'); 
ylabel('Error');
title('Inverse error between sound predicited motoric activity via LMAN to tutor song');
legend('SME between actual sound and sound predicted by via LMAN');

figure(4);
plot(e_weight); 
xlabel('Learning steps'); 
ylabel('Error');
title('Difference between HVC and LMAN weights');
legend('Weights');


